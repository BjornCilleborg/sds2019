{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "**Focus on**:\n",
    "- Quality of data\n",
    "- Log your data and calls when using data scraping\n",
    "- Creativity\n",
    "- Visualization (explanatory figures), simple is better\n",
    "- Be critical of your data collection and generating process\n",
    "    - Bias\n",
    "    - Missing data\n",
    "        - Ignore\n",
    "        - Collect new data\n",
    "        - Remove or replace missing data\n",
    "    - Internal and external validity\n",
    "    - Data collection type (random, survey, big data, other)\n",
    "- Less focus on the analytical section and more on the collection and presentation\n",
    "\n",
    "### Reflect on the ethical aspect\n",
    "- Do you respect privacy? \n",
    "- Can single individuals be identified? \n",
    "- What are the potential consequences?\n",
    "- Are there ethical considerations?\n",
    "    - With respect to individuals? \n",
    "    - With respectto firms or organizations?\n",
    "- Consider the GDPR:\n",
    "    - Is it anonymous? \n",
    "    - Personal data or statistics?\n",
    "    - Any change of re-identification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging\n",
    "\n",
    "- Log your calls, use it to determine success ratio\n",
    "    - Where did the call fail? Rewrite code.\n",
    "    - Don't be greedy. time.sleep(0.5) between each call.\n",
    "- Visualize the log (lecture 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing our data source to Python. The file *tweets.json* is created from [the Trump twitter archive](http://www.trumptwitterarchive.com/archive). We have selected all tweets from the 20th of January 2017 (assumed office) to 21st of August 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DOCSTRING**\n",
    "\n",
    "Below we provide our docstring to the data project.\n",
    "We import the relevant packages, some of which will require installation through either *pip* or *conda*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DOCSTRING:\n",
    "\n",
    "This project analyzes Donald J. Trump's twitter data and presents a visual analysis of key elements.\n",
    "It makes use of several packages, some of which should be installed via either pip or conda.\n",
    "Executing the code cells will save files to the relative path of this Jupyter Notebook. \n",
    "\n",
    "'''\n",
    "\n",
    "# Importing packages\n",
    "import pandas as pd\n",
    "import scraping_class, time, json\n",
    "import numpy as np\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display, HTML\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from afinn import Afinn\n",
    "% matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up our connector to the relevant data source and log our connections in a file called *my_log*. \n",
    "\n",
    "We later use the log file to visualize our data connection attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = 'my_log'## name your log file.\n",
    "connector = scraping_class.Connector(logfile)\n",
    "data = []\n",
    "# Fetching data\n",
    "for i in range(2015,2020):\n",
    "    url = 'http://www.trumptwitterarchive.com/data/realdonaldtrump/'+str(i)+'.json'\n",
    "    r, call_id = connector.get(url, 'Tweets')\n",
    "    json_file = r.json() \n",
    "    data += json_file[::-1] # invert list\n",
    "    time.sleep(0.5) # set sleep timer to prevent unintentional DOS attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and manipulating dataframes\n",
    "# Main dataframe\n",
    "df = pd.DataFrame(data)\n",
    "date = [i[2]+i[1]+i[-1]+'-'+i[3] for i in df['created_at'].str.split(' ')] # slice date\n",
    "df['datetime'] = date\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%d%b%Y-%H:%M:%S') # format datetime \n",
    "#df = df[(df['datetime'] > '2017-01-20')] # filter by relevant date\n",
    "df = df.query(\"is_retweet == False\") # drop retweets\n",
    "df = df.reset_index(drop=True).sort_values(by=['datetime']) # set index to date\n",
    "df.index = df['datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "import fuzzywuzzy\n",
    "\n",
    "def sp500_tickers_names():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    names = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        name  = row.findAll('td')[1].text\n",
    "        tickers.append(ticker)\n",
    "        names.append(name)\n",
    "        \n",
    "    with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)\n",
    "    with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(names,f)\n",
    "        \n",
    "    return tickers, names\n",
    "\n",
    "# ændringer direkte her: skift til AIG, tilføj Google\n",
    "SP500 = sp500_tickers_names()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding names that differ alot from there offical names\n",
    "\n",
    "missing_names = ['Google', 'AIG', 'JPMorgan', 'Microsoft'] \n",
    "for names in missing_names:\n",
    "    SP500.append(names) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 509/509 [34:44<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "#Running the first fuzzy search \n",
    "from fuzzywuzzy import fuzz\n",
    "#################################################################################\n",
    "# Warning may take along time (10**7 iterations) - approx 35 min                #\n",
    "#################################################################################\n",
    "# Refer instead to the pickled file above\n",
    "# Second run-through is on reduced firm sample\n",
    "from tqdm import tqdm\n",
    "relevant_tweet = {}\n",
    "store_count = {}\n",
    "for SP in tqdm(SP500):\n",
    "    count_sp = 0\n",
    "    for i in range(len(df['text'])):\n",
    "        if fuzz.token_set_ratio(df['text'][i], SP)>=60: \n",
    "            count_sp +=1\n",
    "            relevant_tweet[i]=SP\n",
    "    store_count[SP]=count_sp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>American Express Co</th>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT&amp;T Inc.</th>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank of America Corp</th>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Bank of New York Mellon Corp.</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Buy Co. Inc.</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cimarex Energy</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cincinnati Financial</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMS Energy</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Cooper Companies</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Devon Energy</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dollar General</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTE Energy Co.</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duke Energy</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E*Trade</th>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Dynamics</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Electric</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Mills</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Motors</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCA Healthcare</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lincoln National</th>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NextEra Energy</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NRG Energy</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People's United Financial</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public Storage</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sempra Energy</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southern Co.</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twitter, Inc.</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TJX Companies Inc.</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Travelers Companies Inc.</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valero Energy</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   count\n",
       "American Express Co                  205\n",
       "AT&T Inc.                            695\n",
       "Bank of America Corp                 331\n",
       "The Bank of New York Mellon Corp.     63\n",
       "Best Buy Co. Inc.                     67\n",
       "Cimarex Energy                        88\n",
       "Cincinnati Financial                  53\n",
       "CMS Energy                            88\n",
       "The Cooper Companies                 139\n",
       "Devon Energy                          88\n",
       "Dollar General                       177\n",
       "DTE Energy Co.                        88\n",
       "Duke Energy                           88\n",
       "E*Trade                              320\n",
       "General Dynamics                     135\n",
       "General Electric                     144\n",
       "General Mills                        134\n",
       "General Motors                       134\n",
       "HCA Healthcare                       120\n",
       "Lincoln National                     314\n",
       "NextEra Energy                        88\n",
       "NRG Energy                            88\n",
       "People's United Financial             66\n",
       "Public Storage                        76\n",
       "Sempra Energy                         88\n",
       "Southern Co.                         136\n",
       "Twitter, Inc.                         63\n",
       "TJX Companies Inc.                   135\n",
       "The Travelers Companies Inc.         102\n",
       "Valero Energy                         88"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the data frame to see what firms might be problematic\n",
    "df_sc=pd.Series(store_count)\n",
    "df_sc = df_sc.to_frame()\n",
    "df_sc.columns = ['count']\n",
    "df_sc.query('count >50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Used for second round of fuzzy search:\n",
    "non_zero_SP500 = list(df_sc.query(\"count !=0\").index) # Select the companies with non-zero amount of relevant tweets\n",
    "SP500=non_zero_SP500 #Overwriting the old data frame without the companies with no tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Futher changes to the dataframe:\n",
    "# The inspection of the data revealed some problematic companies that had to many false positives\n",
    "# AT&T, Energy, Companies, Trade, facebook, resources, general, healthcare, international, Lincoln, national, technology, public, southern,\n",
    "\n",
    "# We try removing parts of company names that have inherent meaning - the idea is to leave the names of the companies\\\n",
    "# without the word that has inherent meaning - i.e. to search for Ameriprise rather than Ameriprise Financial\n",
    "# This approach is not without its weaknesses - but right now we are getting to many false positives\n",
    "\n",
    "\n",
    "############################## This code was for testing the approach #############################\n",
    "#Initially we create a list of firms affected by this modification:\n",
    "# part_remove = []\n",
    "# for i in range(len(SP500)):\n",
    "#     if any(j in SP500[i].lower() for j in problematic_names):\n",
    "#         part_remove.append(SP500[i])\n",
    "\n",
    "# #We then go over all the firms removing the problematic parts of their names:        \n",
    "# for part in part_remove:\n",
    "#       for problems in problematic_names:\n",
    "#              if problems in part:\n",
    "#                     part_remove[part_remove.index(part)]=part.replace(problems, '')\n",
    "##################################################################################################\n",
    "\n",
    "# Removing the problematic parts \n",
    "# AT&T, Energy, Companies, Trade, facebook, resources, general, healthcare, international, Lincoln, national, technology, public, southern,\n",
    "problematic_names = ['Financial', 'Energy', 'Companies','Corporation', 'Resources', 'National', 'Technology', 'International', 'Company', 'Technologies']\n",
    "for firm in SP500:\n",
    "      for problems in problematic_names:\n",
    "             if problems in firm:\n",
    "                    SP500[SP500.index(firm)]=firm.replace(problems, '')    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237/237 [14:25<00:00,  3.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# We make the fuzzy search again on the data set without the X-irrelevant companies\n",
    "# where we have also removed problematic parts of company names\n",
    "####################################################################################################################\n",
    "# Warning may take along time (approx 15 min) - though it is 237 compared to 509 companies in the first run_through#\n",
    "####################################################################################################################\n",
    "# Refer instead to the pickled file in the hand-in\n",
    "# Second run-through is on reduced firm sample\n",
    "relevant_tweet = {}\n",
    "store_count = {}\n",
    "for SP in tqdm(SP500):\n",
    "    count_sp = 0\n",
    "    for i in range(len(df['text'])):\n",
    "        if fuzz.token_set_ratio(df['text'][i], SP)>=60: \n",
    "            count_sp +=1\n",
    "            relevant_tweet[i]=SP\n",
    "    store_count[SP]=count_sp       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>American Express Co</th>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American  Group</th>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT&amp;T Inc.</th>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank of America Corp</th>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Bank of New York Mellon Corp.</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Buy Co. Inc.</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dollar General</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E*Trade</th>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox  Class A</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox  Class B</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Dynamics</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Electric</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Mills</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Motors</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCA Healthcare</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Packaging  of America</th>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People's United</th>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public Storage</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robert Half</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southern Co.</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twitter, Inc.</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United</th>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   count\n",
       "American Express Co                  205\n",
       "American  Group                      503\n",
       "AT&T Inc.                            695\n",
       "Bank of America Corp                 331\n",
       "The Bank of New York Mellon Corp.     63\n",
       "Best Buy Co. Inc.                     67\n",
       "Dollar General                       177\n",
       "E*Trade                              320\n",
       "Fox  Class A                         110\n",
       "Fox  Class B                          71\n",
       "General Dynamics                     135\n",
       "General Electric                     144\n",
       "General Mills                        134\n",
       "General Motors                       134\n",
       "HCA Healthcare                       120\n",
       "Packaging  of America                330\n",
       "People's United                      337\n",
       "Public Storage                        76\n",
       "Robert Half                           67\n",
       "Southern Co.                         136\n",
       "Twitter, Inc.                         63\n",
       "United                               445"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the data frame to see what firms might be problematic\n",
    "df_sc=pd.Series(store_count)\n",
    "df_sc = df_sc.to_frame()\n",
    "df_sc.columns = ['count']\n",
    "df_sc.query('count >50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After this second runthrough we inspect the relevant_tweets and remove directly from here\n",
    "# A more correct approach would be to make changes to the SP500 we search over and do the search again\n",
    "# But due to time-constrain, this very computationally costly approach is unfeasible\n",
    "\n",
    "# Some companies get a huge amount of false positive due to their name being something with inherent meaning:\n",
    "# After visual inspection of the fuzzy search results, we have added the following exeptions:\n",
    "exeptions = ['american', 'anthem', 'america', 'united']\n",
    "\n",
    "# We create a list so we are able to inspect the amount of tweets we remove, and check companies might be affected\n",
    "remove_ex = {}\n",
    "for i, j in relevant_tweet.items():\n",
    "        if any(ex in relevant_tweet[i].lower() for ex in exeptions):\n",
    "            remove_ex[i]=j\n",
    "#display(remove_ex[0:100]) -> removed firms like: united, packaging of america, American express, american airlines.\n",
    "#Then we remove these tweets from the relevant_tweets using the pop function\n",
    "all(map( relevant_tweet.pop, remove_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beautiful evening at a #MAGARally with great American Patriots. Loyal citizens like you helped build this Country and together, we are taking back this Country – returning power to YOU, the AMERICAN PEOPLE. Get out and https://t.co/0pWiwCHGbh! https://t.co/9nCTLdFVW4 https://t.co/wBOUVedVtT',\n",
       " 'Horrible killing of a 13 year old American girl at her home in Israel by a Palestinian terrorist. We must get tough. https://t.co/zauQ6kb9Hj',\n",
       " 'We pause today to remember the 2,403 American heroes who selflessly gave their lives at Pearl Harbor 75 years ago...\\nhttps://t.co/r5eRLR24Q3',\n",
       " 'It was an honor to host our American heroes from the @WWP #SoldierRideDC at the @WhiteHouse today with @FLOTUS, @VP… https://t.co/u5AI1pupVV',\n",
       " 'Speech transcript at Arab Islamic American Summit ➡️https://t.co/eUWxJXJxbe\\n\\nReplay ➡️https://t.co/VtmlSqciXx\\n\\n#RiyadhSummit #POTUSAbroad']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "2408\n",
      "587\n",
      "1821\n"
     ]
    }
   ],
   "source": [
    "#After removing the exceptions we inspect the relevant_tweets again, and find an amount of tweets on AT&T that indicates problems:\n",
    "#looking at AT&T\n",
    "ATT_tweets=[k for k,v in relevant_tweet.items() if v == 'AT&T Inc.']\n",
    "att_tweets = []\n",
    "#Inserting tweet ID in df['text'] to call tweets\n",
    "for i in ATT_tweets:\n",
    "    att_tweets.append(df['text'][i])\n",
    "    \n",
    "display(att_tweets[0:5]) # Reading over contents\n",
    "# We discover the following issue:\n",
    "print(fuzz.token_set_ratio('Today, I was thrilled to host the @WWP Soldier Ride once again at the @WhiteHouse. We were all deeply honored to be in the presence of TRUE AMERICAN HEROES....https://t.co/q6D5875xCw', 'AT&T'))\n",
    "print(fuzz.token_set_ratio('at', 'AT&T'))\n",
    "#Removing AT&T tweets - since every tweet with the word 'at' will get 100 pct. match\n",
    "print(len(relevant_tweet)) #Checking length before removing\n",
    "print(len(ATT_tweets)) # Amount to be removed\n",
    "all(map(relevant_tweet.pop, ATT_tweets)) #Removing using the pop function over the dict relevant_tweet\n",
    "print(len(relevant_tweet)) # Check if result adds up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am pleased to inform you that I have just named General/Secretary John F Kelly as White House Chief of Staff. He is a Great American....',\n",
       " 'Great meeting with Ford CEO Mark Fields and General Motors CEO Mary Barra at the @WhiteHouse today. https://t.co/T0eIgO6LP8',\n",
       " 'Today, it was an honor to have @UN\\nSecretary-General @AntonioGuterres at the @WhiteHouse. Speaking for the U.S.A., we appreciate all you do! https://t.co/Sk0Jcazzxw',\n",
       " 'When you give a crazed, crying lowlife a break, and give her a job at the White House, I guess it just didn’t work out. Good work by General Kelly for quickly firing that dog!',\n",
       " '“They were all in on it, clear Hillary Clinton and FRAME Donald Trump for things he didn’t do.” Gregg Jarrett on @foxandfriends  If we had a real Attorney General, this Witch Hunt would never have been started! Looking at the wrong people.',\n",
       " '\"@BreitbartVideo: .@AnnCoulter: Trump Has Best Shot in General Election http://t.co/Vf6c5kvrcn via @IanHanchett http://t.co/GOQTWZhjAM\"',\n",
       " '\"@realDBP: @realDonaldTrump @MenOfHistory The Art of the Deal is still the best book ever written on business and life in general!\" Thanks',\n",
       " '\"@USARestoring: @HillaryClinton\\'s toast. Dems had better get the\"B Team\" off the bench. @TGowdySC for Attorney General under President Trump',\n",
       " '\"@gse_says: Overwhelming wins by @realDonaldTrump in primaries will prove what will happen (landslide) in the general election.',\n",
       " 'Ben Carson was speaking in general terms as to what he would do if confronted with a gunman, and was not criticizing the victims. Not fair!',\n",
       " 'Thank you General. #Trump2016 https://t.co/FCrYNoqYTb',\n",
       " 'The polls are now showing that I am the best to win the GENERAL ELECTION. States that are never in play for Repubs will be won by me. Great!',\n",
       " '\"@Vogelsong1: @EdRollins gets it. Was just on @FoxNews explaining how Trump wins the general election.\"  Thank you Ed!',\n",
       " \"Don't believe the @FoxNews Polls, they are just another phony hit job on me. I will beat Hillary Clinton easily in the General Election.\",\n",
       " 'Great honor to have @GOP General Counsel, #JohnRyder as a Trump delegate in TN. RNC meeting well worth it! Unifying the party!',\n",
       " \"The Inspector General's report on Crooked Hillary Clinton is a disaster. Such bad judgement and temperament cannot be allowed in the W.H.\",\n",
       " 'Thank you Attorney General Gonzales, so many people feel this way. \\nhttps://t.co/fMR8YYiiMz',\n",
       " '\"@JimVitari:  @ABC @washingtonpost we know they\\'re fake just like poles during primary. I\\'m sure u will crush #CrookedHillary in general\"',\n",
       " 'The system is rigged. General Petraeus got in trouble for far less. Very very unfair! As usual, bad judgment.',\n",
       " 'I highly recommend the just out book - THE FIELD OF FIGHT - by General Michael Flynn. How to defeat radical Islam.',\n",
       " '\"@Theresa_Cali: @realDonaldTrump General Michael Flynn will make a great Secretary of Defense when you become POTUS! #MakeAmericaSafeAgain\"',\n",
       " 'General John Allen, who I never met but spoke against me last night, failed badly in his fight against ISIS. His record = BAD  #NeverHillary',\n",
       " \"Wow, NATO's top commander just announced that he agrees with me that alliance members must PAY THEIR BILLS. This is a general I will like!\",\n",
       " 'General James \"Mad Dog\" Mattis, who is being considered for Secretary of Defense, was very impressive yesterday. A true General\\'s General!',\n",
       " \"'Jeff Sessions, a Fitting Selection for Attorney General'\\nhttps://t.co/LjKTkAZSFy\",\n",
       " 'during a general election. I, for one, am appalled that somebody that is the nominee of one of our two major parties would take that kind --',\n",
       " 'Just met with General Petraeus--was very impressed!',\n",
       " \"Departing New York with General James 'Mad Dog' Mattis for tonight's rally in Fayetteville, North Carolina! See you… https://t.co/Z8sgJBWI09\",\n",
       " 'General Motors is sending Mexican made model of Chevy Cruze to U.S. car dealers-tax free across border. Make in U.S.A.or pay big border tax!',\n",
       " 'I will be having a general news conference on JANUARY ELEVENTH in N.Y.C. Thank you.',\n",
       " 'The failing @nytimes has been wrong about me from the very beginning. Said I would lose the primaries, then the general election. FAKE NEWS!',\n",
       " \"When will the Democrats give us our Attorney General and rest of Cabinet! They should be ashamed of themselves! No wonder D.C. doesn't work!\",\n",
       " 'Congratulations to our new Attorney General, @SenatorSessions! https://t.co/e0buP1K83z',\n",
       " '..Ryan died on a winning mission ( according to General Mattis), not a \"failure.\" Time for the U.S. to get smart and start winning again!',\n",
       " 'Join us live in the Oval Office for the swearing in of our new Attorney General, @SenatorSessions!\\nLIVE:… https://t.co/QeW6vjog4A',\n",
       " 'Just named General H.R. McMaster National Security Advisor.',\n",
       " 'Congratulations to our new National Security Advisor, General H.R. McMaster. Video: https://t.co/BKn9r225Kk https://t.co/VBXcJ1b6Pv',\n",
       " 'General Kelly is doing a great job at the border. Numbers are way down. Many are not even trying to come in anymore.',\n",
       " 'It was an honor to welcome @GLFOP to the @WhiteHouse today with @VP Pence &amp; Attorney General Sessions. THANK YOU fo… https://t.co/VHzTB4c69h',\n",
       " 'The two fake news polls released yesterday, ABC &amp; NBC, while containing some very positive info, were totally wrong in General E. Watch!',\n",
       " 'General Flynn was given the highest security clearance by the Obama Administration - but the Fake News seldom likes talking about that.',\n",
       " \"General John Kelly is doing a fantastic job as Chief of Staff. There is tremendous spirit and talent in the W.H. Don't believe the Fake News\",\n",
       " 'General John Kelly is doing a great job as Chief of Staff. I could not be happier or more impressed - and this Administration continues to..',\n",
       " 'I will be meeting General Kelly, General Mattis and other military leaders at the White House to discuss North Korea. Thank you.',\n",
       " 'Attorney General Bill Shuette will be a fantastic Governor for the great State of Michigan. I am bringing back your jobs and Bill will help!',\n",
       " 'Attorney General Bill Schuette will be a fantastic Governor for the great State of Michigan. I am bringing back your jobs and Bill will help',\n",
       " 'General John Kelly totally agrees w/ my stance on NFL players and the fact that they should not be disrespecting our FLAG or GREAT COUNTRY!',\n",
       " 'The Fake News is at it again, this time trying to hurt one of the finest people I know, General John Kelly, by saying he will soon be.....',\n",
       " 'After strict consultation with General Kelly, the CIA and other Agencies, I will be releasing ALL #JFKFiles other than the names and...',\n",
       " 'Remarks from the Roosevelt Room with @SenateMajLdr Mitch McConnell, @SpeakerRyan and Secretary of Defense, General James Mattis. https://t.co/lZMqK5jBvh',\n",
       " 'I had to fire General Flynn because he lied to the Vice President and the FBI. He has pled guilty to those lies. It is a shame because his actions during the transition were lawful. There was nothing to hide!',\n",
       " 'So General Flynn lies to the FBI and his life is destroyed, while Crooked Hillary Clinton, on that now famous FBI holiday “interrogation” with no swearing in and no recording, lies many times...and nothing happens to her? Rigged system, or just a double standard?',\n",
       " 'The reason I originally endorsed Luther Strange (and his numbers went up mightily), is that I said Roy Moore will not be able to win the General Election.  I was right! Roy worked hard but the deck was stacked against him!',\n",
       " 'Thank you to General John Kelly, who is doing a fantastic job, and all of the Staff and others in the White House, for a job well done. Long hours and Fake reporting makes your job more difficult, but it is always great to WIN, and few have won more than us!',\n",
       " 'General McMaster forgot to say that the results of the 2016 election were not impacted or changed by the Russians and that the only Collusion was between Russia and Crooked H, the DNC and the Dems. Remember the Dirty Dossier, Uranium, Speeches, Emails and the Podesta Company!',\n",
       " 'Why is A.G. Jeff Sessions asking the Inspector General to investigate potentially massive FISA abuse. Will take forever, has no prosecutorial power and already late with reports on Comey etc. Isn’t the I.G. an Obama guy? Why not use Justice Department lawyers? DISGRACEFUL!',\n",
       " 'I am pleased to announce that, effective 4/9/18, @AmbJohnBolton will be my new National Security Advisor. I am very thankful for the service of General H.R. McMaster who has done an outstanding job &amp; will always remain my friend. There will be an official contact handover on 4/9.',\n",
       " 'James Comey just threw Andrew McCabe “under the bus.” Inspector General’s Report on McCabe is a disaster for both of them! Getting a little (lot) of their own medicine?',\n",
       " 'To the great people of West Virginia we have, together, a really great chance to keep making a big difference. Problem is, Don Blankenship, currently running for Senate, can’t win the General Election in your State...No way! Remember Alabama. Vote Rep. Jenkins or A.G. Morrisey!',\n",
       " 'Rep.Trey Gowdy, “I don’t think so, I think what the President is doing is expressing frustration that Attorney General Sessions should have shared these reasons for recusal before he took the job, not afterward. If I were the President and I picked someone to be the country’s....',\n",
       " 'I can’t think of something more concerning than a law enforcement officer suggesting that their going to use their powers to affect an election!” Inspector General Horowitz on what was going on with numerous people regarding my election. A Rigged Witch Hunt!p',\n",
       " 'Former Attorney General Michael Mukasey said that President Trump is probably correct that there was surveillance on Trump Tower. Actually, far greater than would ever have been believed!',\n",
       " 'Bilateral Breakfast with NATO Secretary General in Brussels, Belgium... https://t.co/l0EP3lzhCM',\n",
       " 'As I head out to a very important NATO meeting, I see that FBI Lover/Agent Lisa Page is dodging a Subpoena &amp; is refusing to show up and testify. What can she possibly say about her statements and lies. So much corruption on the other side. Where is the Attorney General? @FoxNews',\n",
       " 'Congratulations to General John Kelly. Today we celebrate his first full year as @WhiteHouse Chief of Staff! https://t.co/JWCaJ3GhHV',\n",
       " '..This is a terrible situation and Attorney General Jeff Sessions should stop this Rigged Witch Hunt right now, before it continues to stain our country any further. Bob Mueller is totally conflicted, and his 17 Angry Democrats that are doing his dirty work are a disgrace to USA!',\n",
       " '.@LindseyGrahamSC  “Every President deserves an Attorney General they have confidence in. I believe every President has a right to their Cabinet, these are not lifetime appointments. You serve at the pleasure of the President.”',\n",
       " 'Statement from White House Chief of Staff, General John Kelly: https://t.co/LUN8cDr3N5',\n",
       " 'Thank you General Kelly, book is total fiction! https://t.co/J5iUONhRin',\n",
       " 'Thank you General Mattis, book is boring &amp; untrue! https://t.co/Bq79ZjF3Dk',\n",
       " 'So true! “Mr. Trump remains the single most popular figure in the Republican Party, whose fealty has helped buoy candidates in competitive Republican primaries and remains a hot commodity among general election candidates.”  Nicholas Fandos, @nytimes',\n",
       " '“It is mostly anonymous sources in here, why should anyone trust you? General Mattis, General Kelly said it’s not true.” @SavannahGuthrie  @TODAYshow  Bob Woodward is a liar who is like a Dem operative prior to the Midterms. He was caught cold, even by NBC.',\n",
       " 'I met with the DOJ concerning the declassification of various UNREDACTED documents. They agreed to release them but stated that so doing may have a perceived negative impact on the Russia probe. Also, key Allies’ called to ask not to release. Therefore, the Inspector General.....',\n",
       " 'Senator Richard Blumenthal must talk about his fraudulent service in Vietnam, where for 12 years he told the people of Connecticut, as their Attorney General, that he was a great Marine War Hero. Talked about his many battles of near death, but was never in Vietnam. Total Phony!',\n",
       " '....We thank Attorney General Jeff Sessions for his service, and wish him well! A permanent replacement will be nominated at a later date.',\n",
       " '....Mr. Whitaker is very highly thought of by @SenJoniErnst, Senator @ChuckGrassley, Ambassador @TerryBranstad, Leonard Leo of Federalist Society, and many more. I feel certain he will make an outstanding Acting Attorney General!',\n",
       " 'So funny to see little Adam Schitt (D-CA) talking about the fact that Acting Attorney General Matt Whitaker was not approved by the Senate, but not mentioning the fact that Bob Mueller (who is highly conflicted) was not approved by the Senate!',\n",
       " 'General Anthony Tata: “President Trump is a man of his word &amp; he said he was going to be tough on the Border, and he is tough on the Border. He has rightfully strengthened the Border in the face of an unprecedented threat. It’s the right move by President Trump.” Thanks General!',\n",
       " '....for electric cars. General Motors made a big China bet years ago when they built plants there (and in Mexico) - don’t think that bet is going to pay off. I am here to protect America’s Workers!',\n",
       " 'Very disappointed with General Motors and their CEO, Mary Barra, for closing plants in Ohio, Michigan and Maryland. Nothing being closed in Mexico &amp; China. The U.S. saved General Motors, and this is the THANKS we get! We are now looking at cutting all @GM subsidies, including....',\n",
       " 'General Motors is very counter to what other auto, and other, companies are doing. Big Steel is opening and renovating plants all over the country. Auto companies are pouring into the U.S., including BMW, which just announced a major new plant. The U.S.A. is booming!',\n",
       " 'They gave General Flynn a great deal because they were embarrassed by the way he was treated - the FBI said he didn’t lie and they overrode the FBI. They want to scare everybody into making up stories that are not true by catching them in the smallest of misstatements. Sad!......',\n",
       " '“It looks here as though General Flynn’s defenses are incidental to something larger which is for the prosecution to figure out if it can find a path to Donald Trump without quite knowing what that crime might be. It stops looking like prosecution and more looking like......',\n",
       " 'Good luck today in court to General Michael Flynn. Will be interesting to see what he has to say, despite tremendous pressure being put on him, about Russian Collusion in our great and, obviously, highly successful political campaign. There was no Collusion!',\n",
       " '....equipment. General Mattis was a great help to me in getting allies and other countries to pay their share of military obligations. A new Secretary of Defense will be named shortly. I greatly thank Jim for his service!',\n",
       " 'General Jim Mattis will be retiring, with distinction, at the end of February, after having served my Administration as Secretary of Defense for the past two years. During Jim’s tenure, tremendous progress has been made, especially with respect to the purchase of new fighting....',\n",
       " 'General Anthony Tata, author, “Dark Winter.” I think the President is making the exact right move in Syria. All the geniuses who are protesting the withdrawal of troops from Syria are the same geniuses who cooked the books on ISIS intelligence and gave rise to ISIS.”',\n",
       " '....We are substantially subsidizing the Militaries of many VERY rich countries all over the world, while at the same time these countries take total advantage of the U.S., and our TAXPAYERS, on Trade. General Mattis did not see this as a problem. I DO, and it is being fixed!',\n",
       " 'I never “lashed out” at the Acting Attorney General of the U.S., a man for whom I have great respect. This is a made up story, one of many, by the Fake News Media!',\n",
       " '“General” McChrystal got fired like a dog by Obama. Last assignment a total bust. Known for big, dumb mouth. Hillary lover! https://t.co/RzOkeHl3KV',\n",
       " '“If thinking that James Comey is not a good FBI Director is tantamount to being an agent of Russia, than just list all the people that are agents of Russia - Chuck Schumer, Nancy Pelosi, Rod Rosenstein who wrote the memo to get rid of Comey, the Inspector General....” Trey Gowdy',\n",
       " 'Because the economy is so good, General Motors must get their Lordstown, Ohio, plant open, maybe in a different form or with a new owner, FAST! Toyota is investing 13.5 $Billion in U.S., others likewise. G.M. MUST ACT QUICKLY. Time is of the essence!',\n",
       " 'Just spoke to Mary Barra, CEO of General Motors about the Lordstown Ohio plant. I am not happy that it is closed when everything else in our Country is BOOMING. I asked her to sell it or do something quickly. She blamed the UAW Union — I don’t care, I just want it open!',\n",
       " 'General Motors and the UAW are going to start “talks” in September/October. Why wait, start them now! I want jobs to stay in the U.S.A. and want Lordstown (Ohio), in one of the best economies in our history, opened or sold to a company who will open it up fast! Car companies.....',\n",
       " 'Today, it was my great honor to welcome @NATO Secretary General @JensStoltenberg to the @WhiteHouse! https://t.co/4drPHXZBWH',\n",
       " 'Why should Radical Left Democrats in Congress have a right to retry and examine the $35,000,000 (two years in the making) No Collusion Mueller Report, when the crime committed was by Crooked Hillary, the DNC and Dirty Cops? Attorney General Barr will make the decision!',\n",
       " 'Attorney General William Barr’s Press Conference today at 9:30 AM ET. Watch on @FoxNews @OANN',\n",
       " '“The real “Obstruction of Justice” is what the Democrats are trying to do to this Attorney General.” Congressman Jim Jordan (R-Ohio). @MariaBartiromo',\n",
       " 'GREAT NEWS FOR OHIO! Just spoke to Mary Barra, CEO of General Motors, who informed me that, subject to a UAW agreement etc., GM will be selling their beautiful Lordstown Plant to Workhorse, where they plan to build Electric Trucks. GM will also be spending $700,000,000 in Ohio...',\n",
       " '....President who is willing to have the battle, and we have a great Attorney General who is willing to lead the battle, and they are going to get to the bottom of it.” @EdRollins  @LouDobbs',\n",
       " '“It’s the attack strategy of harass. This is not about the Attorney General, who is very sophisticated &amp; knows it isn’t about him, it’s about trying to destroy President Trump through an assault on his AG for upholding the rule of law. He released a massive amount of......',\n",
       " 'It now seems the General Flynn was under investigation long before was common knowledge. It would have been impossible for me to know this but, if that was the case, and with me being one of two people who would become president, why was I not told so that I could make a change?',\n",
       " '....during the 2016 Presidential election. The Attorney General has also been delegated full and complete authority to declassify information pertaining to this investigation, in accordance with the long-established standards for handling classified information....',\n",
       " 'General Michael Flynn, the 33 year war hero who has served with distinction, has not retained a good lawyer, he has retained a GREAT LAWYER, Sidney Powell. Best Wishes and Good Luck to them both!',\n",
       " 'It is very hard and expensive to live in New York. Governor Andrew Cuomo uses his Attorney General as a bludgeoning tool for his own purposes. They sue on everything, always in search of a crime. I even got sued on a Foundation which took Zero rent &amp; expenses &amp; gave away...',\n",
       " 'The Republican Party has a new STAR, his name is Daniel Cameron (@djaycameron), and he is running for Attorney General of the Commonwealth of Kentucky....',\n",
       " 'The Legendary Henry Ford and Alfred P. Sloan, the Founders of Ford Motor Company and General Motors, are “rolling over” at the weakness of current car company executives willing to spend more money on a car that is not as safe or good, and cost $3,000 more to consumers. Crazy!']"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We reuse the approach used on AT&T on the following:\n",
    "# Third inspection indicates we scould inspect the following companies: \n",
    "problem_comp = ['Dollar General', 'E*Trade', 'Fox  Class A', 'General Dynamics', 'General Electric',\\\n",
    "                'General Mills', 'General Motors','HCA Healthcare', 'Southern Co.', 'Chubb Limited', 'CVS Health', 'Juniper Networks']\n",
    "problem_tweets = {}\n",
    "problem_list = {}\n",
    "for comp in problem_comp:\n",
    "    problem_list[comp] = [k for k,v in relevant_tweet.items() if v == str(comp)]\n",
    "    problem_tweets[comp] = [df['text'][k] for k,v in relevant_tweet.items() if v == str(comp)]\n",
    "\n",
    "# This step requires manually inputting the firm-key for inspection since the full amount of tweets at once\n",
    "# are too much to show/consider at once. \n",
    "problem_tweets['General Motors']\n",
    "\n",
    "#problem_list[1]\n",
    "\n",
    "# Below are the conclusions regarding the relevance of the individual firm\n",
    "# Manually looking through reveals:\n",
    "# \n",
    "#Dollar General\tNot working?\n",
    "#E*Trade\tIrrelevant\n",
    "#Fox Class A\tRelevant (considering fox news is part of Fox Class A)\n",
    "#General Dynamics\tNot working?\n",
    "#General Electric\tIrrelevant\n",
    "#General Mills\tNot working?\n",
    "#General Motors\t Partially relevant\n",
    "#HCA Healthcare\tIrrelevant\n",
    "#Southern Co.\tIrrelevant\n",
    "#Chubb Limited \tIrrelevant\n",
    "#CVS Health \t Irrelevant\n",
    "#Juniper Networks \t Irrelevant\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the conclusions above we remove the following firms:\n",
    "tweets_to_remove = []\n",
    "irrelevant_comps = ['E*Trade', 'General Electric','HCA Healthcare', 'Southern Co.', 'Chubb Limited', 'CVS Health', 'Juniper Networks']\n",
    "for comp in irrelevant_comps:\n",
    "     for k,v in problem_list.items():\n",
    "            if k==comp:\n",
    "                tweets_to_remove.append(v)\n",
    "\n",
    "\n",
    "for i in range(len(tweets_to_remove)):\n",
    "     all(map(relevant_tweet.pop, tweets_to_remove[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tiffany & Co.': 4,\n",
       " 'Comcast Corp.': 8,\n",
       " 'Snap-on': 1,\n",
       " 'The Cooper ': 6,\n",
       " 'Wynn Resorts Ltd': 4,\n",
       " 'A.O. Smith Corp': 2,\n",
       " 'Jack Henry & Associates': 3,\n",
       " 'Google': 26,\n",
       " 'Lincoln ': 13,\n",
       " 'Capital One ': 9,\n",
       " 'Duke ': 3,\n",
       " 'Lockheed Martin Corp.': 3,\n",
       " 'Visa Inc.': 11,\n",
       " 'Western Union Co': 12,\n",
       " 'Discovery Inc. Class C': 3,\n",
       " 'The Walt Disney ': 4,\n",
       " 'UDR, Inc.': 2,\n",
       " 'Dow Inc.': 17,\n",
       " 'Nasdaq, Inc.': 6,\n",
       " 'Block H&R': 7,\n",
       " \"Macy's Inc.\": 14,\n",
       " 'Kimberly-Clark': 2,\n",
       " 'Huntington Bancshares': 2,\n",
       " 'Globe Life Inc.': 1,\n",
       " 'Vulcan Materials': 1,\n",
       " 'PNC  Services': 7,\n",
       " 'Starbucks Corp.': 1,\n",
       " 'Boston Properties': 5,\n",
       " 'Under Armour Class C': 2,\n",
       " 'Mettler Toledo': 6,\n",
       " 'Harley-Davidson': 6,\n",
       " 'Sealed Air': 3,\n",
       " 'Tapestry, Inc.': 1,\n",
       " 'Unum Group': 48,\n",
       " \"Edison Int'l\": 1,\n",
       " 'Texas Instruments': 1,\n",
       " 'Valero ': 1,\n",
       " 'Exxon Mobil Corp.': 1,\n",
       " 'Equity Residential': 7,\n",
       " 'Alexandria Real Estate Equities': 1,\n",
       " 'Home Depot': 1,\n",
       " 'TripAdvisor': 5,\n",
       " 'Intercontinental Exchange': 1,\n",
       " 'Eastman Chemical': 5,\n",
       " 'Public Storage': 72,\n",
       " 'Marathon Petroleum': 2,\n",
       " 'Church & Dwight': 6,\n",
       " 'Darden Restaurants': 1,\n",
       " 'Dollar Tree': 32,\n",
       " 'Facebook, Inc.': 27,\n",
       " 'Kellogg Co.': 1,\n",
       " 'General Motors': 107,\n",
       " 'Southwest Airlines': 9,\n",
       " 'Merck & Co.': 2,\n",
       " 'Fox  Class B': 63,\n",
       " 'Best Buy Co. Inc.': 58,\n",
       " 'Williams Cos.': 14,\n",
       " 'PayPal': 1,\n",
       " 'Ulta Beauty': 12,\n",
       " 'Wells Fargo': 3,\n",
       " 'Western Digital': 1,\n",
       " 'Robert Half ': 65,\n",
       " 'Franklin ': 15,\n",
       " 'Apple Inc.': 8,\n",
       " 'Pfizer Inc.': 4,\n",
       " 'T-Mobile US': 15,\n",
       " '3M ': 2,\n",
       " 'Goldman Sachs Group': 7,\n",
       " \"McDonald's Corp.\": 1,\n",
       " 'Tyson Foods': 4,\n",
       " 'Ford Motor': 2,\n",
       " 'Genuine Parts': 2,\n",
       " 'Waters ': 13,\n",
       " 'Ross Stores': 5,\n",
       " 'The Travelers  Inc.': 1,\n",
       " 'Electronic Arts': 2,\n",
       " 'Fortune Brands Home & Security': 1,\n",
       " 'Kraft Heinz Co': 1,\n",
       " 'The Hershey ': 2,\n",
       " ' Paper': 21,\n",
       " 'Kansas City Southern': 2,\n",
       " 'Cincinnati ': 12,\n",
       " 'S&P Global, Inc.': 22,\n",
       " 'Johnson Controls ': 12,\n",
       " 'Total System Services': 2,\n",
       " 'Expedia Group': 1,\n",
       " 'Twitter, Inc.': 58,\n",
       " 'Skyworks Solutions': 12,\n",
       " 'V.F. Corp.': 1,\n",
       " 'Intel Corp.': 10,\n",
       " \"Marriott Int'l.\": 1,\n",
       " 'News Corp. Class B': 2,\n",
       " 'Nordstrom': 2,\n",
       " 'Monster Beverage': 13,\n",
       " 'Rollins Inc.': 2,\n",
       " 'Waste Management Inc.': 16,\n",
       " 'Yum! Brands Inc': 1,\n",
       " 'Nike': 3,\n",
       " 'Ball Corp': 12,\n",
       " 'AIG': 1,\n",
       " 'Kinder Morgan': 1,\n",
       " 'Intl Flavors & Fragrances': 1,\n",
       " 'Broadcom Inc.': 1,\n",
       " 'FLIR Systems': 2,\n",
       " 'Nielsen Holdings': 2,\n",
       " 'AvalonBay Communities, Inc.': 21,\n",
       " 'Dish Network': 30,\n",
       " 'M&T Bank Corp.': 5,\n",
       " 'Progressive Corp.': 2,\n",
       " 'Walmart': 2,\n",
       " 'Lam Research': 14,\n",
       " 'Cabot Oil & Gas': 2,\n",
       " 'Boeing ': 7,\n",
       " 'Sempra ': 1,\n",
       " 'Amazon.com Inc.': 19,\n",
       " 'Phillips 66': 1,\n",
       " 'Eaton ': 1,\n",
       " 'PPG Industries': 9,\n",
       " 'Morgan Stanley': 8,\n",
       " 'Fox  Class A': 36,\n",
       " 'The Bank of New York Mellon Corp.': 48,\n",
       " 'Target Corp.': 5,\n",
       " 'Verizon Communications': 2,\n",
       " 'Humana Inc.': 5,\n",
       " 'Realty Income ': 8,\n",
       " 'Dover Corp.': 1,\n",
       " 'Arthur J. Gallagher & Co.': 5}"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspecting the relevant_tweet frame\n",
    "df_rele=pd.Series(relevant_tweet)\n",
    "df_rele = df_rele.to_frame()\n",
    "df_rele.columns = ['Company']\n",
    "df_rele.head(10)\n",
    "\n",
    "# We checking the reduced relevant_tweet frame for how many times the unique companies are mentioned:\n",
    "store_counts_rele = {}\n",
    "for i in set(df_rele['Company']):\n",
    "    count = 0\n",
    "    for j in df_rele.index:\n",
    "        if df_rele['Company'][j]==str(i):\n",
    "            count+=1\n",
    "    store_counts_rele[i]=count\n",
    "\n",
    "store_counts_rele\n",
    "#Inspection of these results indicate that the following companies produce to many false positives:\n",
    "#Unum Group, Public Storage, Dollar, Best Buy Co. Inc, Robert Half, Paper, Dish Network, The Bank of New York mellon Corp, lam Research, ball C\n",
    "#General Motors - we still haven't solved that theese were partially relevant (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At stake in this Election is whether we continue the extraordinary prosperity we have achieved - or whether we let the Radical Democrat Mob take a giant wrecking ball to our Country and our Economy! #JobsNotMobs https://t.co/POhRivI1BZ',\n",
       " 'I wonder if Marshawn Lynch will now speak and call some  coach a moron for not allowing him to run the ball three times for one yard?',\n",
       " '\"@ElianaBenador: #CPAC th crystal ball to see th future: True Conservative candidates will be sorely missing. None of them measures toTrump',\n",
       " 'Placing the ball in the right position for the next shot is eighty percent of winning golf. -- Ben Hogan',\n",
       " '.@TMobile  You service is absolutely terrible - get on the ball!  @JohnLegere',\n",
       " '\"@RockinJoe1: @realDonaldTrump your candidacy would hit the GOP like a wrecking ball! Total game changer\"  Stay tuned!',\n",
       " 'Tom Brady would have won if he was throwing a soccer ball. He is my friend and a total winner! @Patriots',\n",
       " '\"@thatgirlflorida: @realDonaldTrump @ByronYork @CBSNews @CNN Florida Loves Trump !!! We had a ball in Jacksonville Saturday! 🚂☁🇺🇸🇺🇸\"',\n",
       " '\"@mathewjmari: On @FaceTheNation #MattSchlapp was on the ball &amp; #jenniferrubin is in a time warped stupor. @realDonaldTrump will EXPAND #GOP',\n",
       " 'Now that the three basketball players are out of China and saved from years in jail, LaVar Ball, the father of LiAngelo, is unaccepting of what I did for his son and that shoplifting is no big deal. I should have left them in jail!',\n",
       " '....untruthful slime ball who was, as time has proven, a terrible Director of the FBI. His handling of the Crooked Hillary Clinton case, and the events surrounding it, will go down as one of the worst “botch jobs” of history. It was my great honor to fire James Comey!',\n",
       " 'Go out and get Andrew McCarthy’s new book, “Ball of Collusion.” “Supervision became the investigator, and when they pushed the envelope, there was nobody there to tell them NO. It goes right to the President (Obama). Plenty of information that Obama was informed &amp; knew exactly...']"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fourth round of inspection indicates we should inspect the following companies: \n",
    "problem_comp4 = ['Unum Group', 'Public Storage', 'Dollar Tree', 'Best Buy Co. Inc.',\\\n",
    "                'Robert Half ','AvalonBay Communities, Inc.',\\\n",
    "                ' Paper','Waters ', 'Dish Network', 'The Bank of New York Mellon Corp.','Lam Research', 'Ball Corp']\n",
    "problem_tweets4 = {}\n",
    "problem_list4 = {}\n",
    "for comp in problem_comp4:\n",
    "    problem_list4[comp] = [k for k,v in relevant_tweet.items() if v == str(comp)]\n",
    "    problem_tweets4[comp] = [df['text'][k] for k,v in relevant_tweet.items() if v == str(comp)]\n",
    "    \n",
    "problem_tweets4['Ball Corp']\n",
    "#problem_list4\n",
    "\n",
    "# Manually looking through reveals:\n",
    "# Conclusions:\n",
    "#Unum Group\tIrrelevant (only group)\n",
    "#Public Storage\tIrrelevant (Only public)\n",
    "#Dollar Tree\tIrrelevant ( only dollar)\n",
    "#Best Buy Co. Inc.\tIrrelevant (only best or buy)\n",
    "#Robert Half \tIrrelevant (Robert Mueller tweets)\n",
    "#AvalonBay Communities, Inc.\tIrrelevant (only communities)\n",
    "#Paper\t Irrelevant (about newspapers)\n",
    "#Waters\tIrrelevant\n",
    "#Dish Network.\tIrrelevant (only network)\n",
    "#The Bank of New York Mellon Corp. \tIrrelevant (only bank and new york)\n",
    "#Lam Research \t Irrelevant (only research)\n",
    "#Ball Corp \t Irrelevant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove tweets according to the conclusion to the search above\n",
    "tweets_to_remove4 = []\n",
    "irrelevant_comps4 = ['Unum Group', 'Public Storage', 'Dollar Tree', 'Best Buy Co. Inc.',\\\n",
    "                'Robert Half ','AvalonBay Communities, Inc.',\\\n",
    "                ' Paper','Waters ', 'Dish Network', 'The Bank of New York Mellon Corp.','Lam Research', 'Ball Corp']\n",
    "for comp in irrelevant_comps4:\n",
    "     for k,v in problem_list4.items():\n",
    "            if k==comp:\n",
    "                tweets_to_remove4.append(v)\n",
    "\n",
    "for i in range(len(tweets_to_remove4)):\n",
    "     all(map(relevant_tweet.pop, tweets_to_remove4[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last thing we fix is the General Motors problem where we found some tweets we relevant,\n",
    "# and we were reluctant to remove them all\n",
    "# Trying to identify the relevant general motors tweets: \n",
    "problem_gen_id_tweet = {}\n",
    "for k,v in relevant_tweet.items():\n",
    "    if v == 'General Motors':\n",
    "        problem_gen_id_tweet[k]=df['text'][k]\n",
    "\n",
    "# After manuel inspection we have determined the following keywords to avoid irrelevant tweets\n",
    "\n",
    "keywords = ['Barra', '@GM', 'Motors', 'G.M.']\n",
    "save_gen = []    \n",
    "for k, v in problem_gen_id_tweet.items():\n",
    "          if any(key in v for key in keywords):\n",
    "              save_gen.append(k)\n",
    "            \n",
    "all(map(problem_gen_id_tweet.pop, save_gen)) #Removing the relevant tweets from our problem_GM_tweets\n",
    "all(map(relevant_tweet.pop, problem_gen_id_tweet)) #Removing the irrelevant tweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pickle the resulting dictionary as not to require anyone to run the fuzzysearch\n",
    "pickle.dump(relevant_tweet, open( \"Final_tweet_GMfix.p\", \"wb\" ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final_GMfix = {}\n",
    "for k,v in relevant_tweet.items():\n",
    "    tweets_final_GMfix[df['text'][k]] = v\n",
    "\n",
    "# We pickle the tweets aswell    \n",
    "pickle.dump(tweets_final_GMfix, open( \"tweets_final_GMfix.p\", \"wb\" ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_tweet_load = pickle.load( open( \"Final_tweet_GMfix.p\", \"rb\" ) )\n",
    "tweets_final_GMfix_load = pickle.load(open(\"tweets_final_GMfix.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_tweet_load == relevant_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_final_GMfix_load == tweets_final_GMfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
