{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "import scraping_class\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd, pprint\n",
    "import requests\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "logfile = 'my_log'## name your log file.\n",
    "connector = scraping_class.Connector(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "relevant_df = pickle.load( open( \"df_relevant.p\", \"rb\" ) )\n",
    "tickers = relevant_df['Ticker']\n",
    "\n",
    "relevant_dates = list(relevant_df['Timestamp'])\n",
    "relevant_dates_f = [str(t) for t in relevant_dates]\n",
    "\n",
    "\n",
    "relevant_dates_0_200 = relevant_dates_f[0:200]\n",
    "relevant_dates_200_400 = relevant_dates_f[200:400]\n",
    "relevant_dates_400_600 = relevant_dates_f[400:600]\n",
    "relevant_dates_600_ = relevant_dates_f[600:]\n",
    "\n",
    "print (len(relevant_dates_0_200))\n",
    "print (len(relevant_dates_200_400))\n",
    "print (len(relevant_dates_400_600))\n",
    "print (len(relevant_dates_600_))\n",
    "\n",
    "tickers_0_200 = tickers[0:200]\n",
    "tickers_200_400 = tickers[200:400]\n",
    "tickers_400_600 = tickers[400:600]\n",
    "tickers_600_ = tickers[600:]\n",
    "\n",
    "company_dict = dict(zip(relevant_dates_f,tickers))\n",
    "company_dict_1 = dict(zip(relevant_dates_0_200,tickers_0_200))\n",
    "company_dict_2 = dict(zip(relevant_dates_200_400,tickers_200_400))\n",
    "company_dict_3 = dict(zip(relevant_dates_400_600,tickers_400_600))\n",
    "company_dict_4 = dict(zip(relevant_dates_600_,tickers_600_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/197 [00:14<48:35, 14.87s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c50323579db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# fetch the stock data for the companies and store them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtwitter_daily_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany_dict_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c50323579db3>\u001b[0m in \u001b[0;36mprocess_range\u001b[0;34m(id_range, store)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "apikey = \"Z6OIONR9OK9RAHMX\"\n",
    "def process_range(id_range, store=None):\n",
    "    \"\"\"process a number of ids, storing the results in a dict\"\"\"\n",
    "    if store is None:\n",
    "        store = {}\n",
    "    for key, value in tqdm(id_range.items()):\n",
    "        r, call_id = connector.get(\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=\"+value+\"&outputsize=full&interval=15min&apikey=\"+apikey, key)\n",
    "        json_file = r.json()\n",
    "        store[key] = json_file\n",
    "        time.sleep(13)\n",
    "    return store\n",
    "\n",
    "# create a dictionary from the relevant tweets that consist of company tickers and date for tweet\n",
    "relevant_df = pickle.load( open( \"df_relevant.p\", \"rb\" ) )\n",
    "tickers = relevant_df['Ticker']\n",
    "relevant_dates = list(relevant_df['Timestamp'])\n",
    "relevant_dates_f = [str(t) for t in relevant_dates]\n",
    "company_dict = dict(zip(relevant_dates_f,tickers))\n",
    "\n",
    "# fetch the stock data for the companies and store them \n",
    "twitter_daily_data = process_range(company_dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the specific tweets should be provided alongside a timestamp from the day it was tweeted. use a for loop to\n",
    "# store only the company's data from around the time the tweet was sent. \n",
    "\n",
    "df_complete = pd.DataFrame() #create empty dataframe to store final values\n",
    "data = []\n",
    "dict_complete_abs = {}\n",
    "\n",
    "#define function to determine a bool that is either 1 or 0, depending on whether the pct. change is pos or neg\n",
    "\n",
    "def pct_bool(df):\n",
    "    pct_bool = []\n",
    "\n",
    "    for x in df_date['pct_change']:\n",
    "        if x > 0:\n",
    "            pct_bool.append(1)\n",
    "        else:\n",
    "            pct_bool.append(0)\n",
    "\n",
    "    df_date[\"pct_bool\"] = pct_bool\n",
    "\n",
    "# loop through the companies and their symbole\n",
    "for key, value in company_dict_test.items():\n",
    "    start_data = twitter_daily_data[key]['Time Series (Daily)']\n",
    "    df = pd.DataFrame(start_data)\n",
    "    df = df.T\n",
    "    df['dates'] = df.index\n",
    "    date = key[:10]\n",
    "    df_date = df[date:date]\n",
    "    df_date = df_date.iloc[:,[0,4,5,8]]\n",
    "   \n",
    "                         \n",
    "    stock_open = df_date['1. open'].astype(float)\n",
    "    stock_close = df_date['5. adjusted close'].astype(float)\n",
    "    df_date['pct_change'] = (stock_open-stock_close)/stock_open\n",
    "    pct_bool(df_date)\n",
    "    df_date['ticker']=company_dict_test[key]\n",
    "    df_date['1. open'] = df_date['1. open'].astype(float)\n",
    "    df_date['5. adjusted close'] = df_date['5. adjusted close'].astype(float)\n",
    "    df_date['6. volume'] = df_date['6. volume'].astype(float)\n",
    "    \n",
    "    frames = [df_complete,df_date]\n",
    "    df_complete = pd.concat(frames)\n",
    "    \n",
    "del df_complete['dates']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
